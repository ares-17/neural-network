\chapter{Implementazione}
Il progetto è scritto in \href{https://www.python.org/downloads/release/python-3110/}{Python 3.11} e segue le caratteristiche introdotte, rimanendo flessibile per l'introduzione di nuove feature. La libreria magiormente utilizzata è \texttt{numpy} che favorisce la scrittura di codice meno propenso ad errori offrendo metodi in grado di ottimizzare i calcoli compiuti. \\
Di seguito una breve introduzione della disposizione e caratteristiche dei file:
\begin{itemize}
    \item \textbf{main.py} : inizializza gli oggetti principali ed esegue la fase di addestramento della rete in base ai parametri definiti, per poi valutarne i risultati
    \item \textbf{train.py} : definizione dei metodi per la fase di addestramento oltre che funzioni di attivazione e di errore
    \item package \textbf{model}:
    \begin{itemize}
        \item \textbf{Dataset.py}: carica il dataset MNIST negli insiemi train, validation, error con i corrispettivi insiemi di valori target 
        \item \textbf{Analysis.py} : definisce metodi per la creazione di grafici comparativi
        \item \textbf{Layer.py} : astrae e incapsula uno strato (interno o non che sia), fornendo i metodi per la fase di addestramento
        \item \textbf{Properties.py} : definizione di metodi per lettura dei parametri di test stabiliti.
    \end{itemize}
\end{itemize}

\subsection{Definizione parametri}
Il paragrafo della definizione dei parametri è anteposto ad altri di maggiore importanza per consentire al lettore una facile interpretazione dei paragrafi successivi. \\
I parametri sono definiti nel file \underline{properties.ini} nella seguente forma:
\begin{lstlisting}[language=C]
[main]
configuration = test
...
[test]
neurons = 10
momentum =  0
epochs = 100
learning_rate = 0.0001
act_functions = tanh, identity
error_function = cross-entropy-softmax
\end{lstlisting}
Dove il valore definito in \texttt{configuration} indica quale serie di parametri sono considerati, in tal caso quelli contenuti nel gruppo "test". \\
La variabile \texttt{neurons} indica il numero di neuroni contenuti nel singolo strato interno, mentre lo strato di output è composto in ogni modo da 10 neuroni.\\
La variabile \texttt{momentum} è un gruppo di valori, separati da virgole, che indica per ogni iterazione del test quali valori considerare. A tutti gli strati sono associati gli stessi valori del momentum considerato. \\
Il termine \texttt{epochs} indica il numero di epoche applicate a tutti i casi di test. \\
Il \texttt{learning\_rate} indica la serie di valori da considerare nell'aggiornamento dei pesi. Ogni valore è considerato sull'intera rete. \\
\texttt{act\_functions} specifica le due funzioni di attivazioni considerate rispettivamente per lo strato interno e lo strato di output. \\
\texttt{error\_function} indica quale funzione di errore utilizzare. La scelta ricade tra : \texttt{cross-entropy} , \texttt{cross-entropy-softmax}, \texttt{mean-square-error}. Per ottenere risultati consistenti l'analisi è proposta con la funzione \texttt{cross-entropy-softmax} come funzione di errore e \texttt{tanh} e \texttt{identità} come funzioni di attivazione.

\subsection{Creazione della rete}
La creazione della rete si basa sulla definizione dello strato interno e dello strato di output specificando le funzioni di attivazione, le corrispettive derivate, nonché il numero di neuroni dello strato interno.
\begin{lstlisting}[language=Python]
def get_layers(neurons, momentum, columns):
    return [
        Layer((neurons, columns), ReLU, ReLU_deriv, momentum), 
        Layer((10, neurons), softmax, ReLU_deriv, momentum)
    ]
\end{lstlisting}
Il parametro \texttt{neurons} contiene il numero di neuroni definito nel file \underline{properties.ini}, mentre \texttt{columns} il numero di feature dello strato di input che nel dataset MNIST corrisponde a 28x28 celle di una singola immagine. \\
L'istanziazione della classe \texttt{Layer} avviene con la chiamata al costruttore:
\begin{lstlisting}[language=Python]
class Layer:
    def __init__(self, shape, activation, derivative, momentum=0):
        self.W = np.random.normal(0, 0.1, (shape[0], shape[1]))
        self.B = np.random.normal(0, 0.1, (shape[0], 1))
        self.activation = activation
        self.derivative = derivative
        self.momentum = momentum
        self.dW_prev = np.zeros_like(self.W)
        self.db_prev = np.zeros_like(self.B)
        self.A, self.Z, self.dZ, self.db, self.dW = None, None, None, None, None
\end{lstlisting}
Le matrici di pesi e bias sono definite con valori generati casualmente seguendo una distribuzione uniforme gaussiana. I membri \texttt{dW\_prev} e \texttt{db\_prev} definiscono la derivata dei pesi precedente e la derivata dei bias precedente ed hanno le stesse dimensioni matriciali delle rispettive matrici. Essi risultano utili nel calcolo dell'aggiornamento dei pesi applicando il momentum. \\

\subsection{Fase di Training}
La fase di training è definita dal metodo principale \texttt{train} e definisce i passaggi base dell'algoritmo.
\begin{lstlisting}[language=Python]
def train(ds,layers,alpha,iterations,error_function):
    accuracy, error_train, error_valid = #... empty arrays
    for i in range(iterations):
        forward_prop(ds.train_data, layers)
        backward_prop(ds.train_data, ds.train_label ..)
        update_params(alpha, layers)

        accuracy[i] = current_accuracy(ds.test...)
        error_train[i] = get_error(ds.train ...)
        error_valid[i] = get_error(ds.valid ... )

    return error_train, error_valid, accuracy.max()
\end{lstlisting}
Per ogni iterazione è compiuta una predizione per ogni input del dataset chiamando il metodo \texttt{forward\_prop}, per poi eseguire l'algoritmo di back propagation determinando l'errore compiuto. Dall'errore compiuto sono calibrati valori dei pesi e dei basi con il metodo \texttt{update\_params}. \\
Il metodo di propagazione in avanti è definito come :
\begin{lstlisting}[language=Python]
def forward_prop(X, layers):
    input_layer = X
    for layer in layers:
        layer.forward_prop(input_layer)
        input_layer = layer.A

class Layer:
    # ... other functions
    def forward_prop(self, input):
        self.Z = self.W.dot(input) + self.B
        self.A = self.activation(self.Z)
\end{lstlisting}
Nel quale ad ogni passo è ridefinita la variabile \texttt{input\_layer} come output dello strato precedente, assegnando allo strato successivo i valori del dataset. \\
L'algoritmo di back propagation è definito come:
\begin{lstlisting}[language=Python]
def backward_prop(X, one_hot_Y, layers, error_deriv):
    input_layers = [X]
    for index in range(len(layers) - 1):
        input_layers.append(layers[index].Z)
    
    dZ = error_deriv(layers[-1].Z , one_hot_Y) *
        layers[-1].derivative(layers[-1].A)
    for index in range(len(layers) - 1, -1, -1):
        current = layers[index]
        current.backward_prop(dZ, input_layers[index])
        if index - 1 > - 1:
            dZ = current.W.T.dot(dZ) *
                layers[index-1].derivative(layers[index-1].A)

class Layer:
    # ... other functions
    def backward_prop(self, dZ, input, m):
        self.dZ = dZ
        self.dW = self.dZ.dot(input.T)
        self.db = np.sum(self.dZ)
\end{lstlisting}
La funzione raccoglie prima i valori di output di ogni strato nel vettore \texttt{input\_layers} per poi calcolare i valori delta $\delta$ e le corrispettive derivate delle funzioni di attivazione sui valori di output determinati. Il ciclo sfrutta di passi i iterazione per determinare il delta dello strato successivo iterando la rete dall'ultimo al primo strato. \\
La definizione delle funzioni si basa sul calcolo ricorsivo del delta per lo strato corrente.
Il delta è calcolato secondo due regole che discriminano la tipologia di strato sul quale è calcolato; da qui in poi $\delta_L$ denota il valore calcolato sull'ultimo strato, $\delta_h$ denota il valore di uno dei qualsiasi strati interni.
\begin{align*}
\delta_L = g^{\prime}_L(A^L) * \frac{\partial E}{\partial y_k}
\end{align*}
Nella formula il primo termine indica la derivata della funzione di attivazione dello strato di output , il secondo indica la derivata della funzione di errore rispetto al valore di uscita prodotto dallo strato. \\
La seguente formula descrive il calcolo del delta per gli strati interni:
\begin{align*}
\delta_i^l = g^{\prime}_h(a^l_i) * \sum^{ml+1}_{j=1}{W_{j,i}^{l+1} \delta_j^{l+1}}
\end{align*}
I pedici $i$ e $j$ indicano i neuroni considerati. Al contempo considerando $A^l$ come la matrice degli input, $W^l$ matrice dei pesi e $\delta^l$ i delta dei neuroni dello strato corrente, allora :
\begin{align*}
\delta^l = g^{\prime}_h(A^l) * (W^{l+1})^T \delta^{l+1}
\end{align*}
L'algoritmo della back propagation implementato sfrutta proprio il concetto di matrici: i dati sono raggruppati in matrici facilitando la scrittura del codice e ottenendo una maggiore efficienza in combinazione con un aggiornamento di tipo batch.\\
L'algoritmo di aggiornamento dei pesi si basa su un aggiornamento di tipo \underline{batch}: tutti i pesi della rete sono aggiornati simultaneamente dopo aver derivato l'errore compiuto durante la singola iterazione d'apprendimento.\\
L'algoritmo di aggiornamento è composto da:
\begin{lstlisting}[language=Python]
def update_params(alpha, layers):
    for layer in layers:
        layer.update_params(alpha)

class Layer:
    # ... other functions
    def update_params(self, alpha):
        self.dW = self.momentum * self.dW_prev
            - alpha * self.dW
        self.db = self.momentum * self.db_prev 
            - alpha * self.db
        self.W += self.dW
        self.B += self.db
\end{lstlisting}
La regola applicata è la seguente:
\begin{align*}
w_{i,j} = w_{i,j} (- \eta * \frac{d}{dw_{i,j}}E^t + \alpha \cdot \Delta w_{i,j}^{t-1})
\end{align*}
La regola di aggiornamento della discesa del gradiente, applicata considerando il parametro \texttt{momento}, considera il precedente valore assunto dal parametro con un tasso variabile indicato proprio dal momento $\alpha$. Il parametro risulta particolarmente utile per superare regioni di plateau, dove il valore e la direzione del peso rimangono invariati.  \\
La regola della discesa del gradiente deriva il nuovo valore assoluto dalla moltiplicazione tra \texttt{learing\_rate} e derivata parziale della funzione di errore rispetto al peso corrente $w_{i,j}$. Un learning rate alto può portare una rapida convergenza del modello, rischiando di saltare un eventuale minimo globale o di oscillare intorno ad esso. Al contempo un valore basso per un caso specifico può causare aggiornamenti più piccoli, rallentando la convergenza. Allo stesso modo è di cruciale importanza porre un giusto valore al parametro $\alpha$.

\subsection{Funzioni applicate}
Di seguito sono presentate le funzioni applicate durante la fase di training e di evaluation dei risultati ottenuti, correlate da definizione matematica. Le funzioni denotate con $'$ sono le corrispondenti derivate parziali della funzione in esame.
\subsubsection{Funzione softmax}
La funzione softmax è una funzione applicata all'output della rete con lo scopo di \underline{normalizzare i risultati} ottenuti durante il processo di training. Il processo di normalizzazione applicato dalla funzione deriva da valori grezzi ricavati dai nodi di output di una rete, applicata su un problema di classificazione, e produce un vettore di probabilità che indica quanto l'input in esame appartenga alla classe considerata. Formula matematica:
\begin{align*}
\text{S}(z_i) = \frac{e^{z_i}}{\sum_{j=1}^{N} e^{z_j}}
\end{align*}
L'input $z_i$ della funzione è l'output di un nodo dell'ultimo strato e tale valore utilizzato come esponente di $e$ è diviso dalla somma di tutti i valori di output anch'essi posti come esponente della costante $e$.
\subsubsection{Funzione tanh}
La funzione tanh calcola la tangente iperbolica del valore di input. La tangente iperbolica è una funzione che mappa i valori in un intervallo compreso tra -1 e 1 ed è simmetrica rispetto all'origine.\\
Formule:
Formula matematica:
\begin{align*}
\text{tanh}(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} 
\end{align*}
\begin{align*}
\text{tanh}^{\prime}(x) = 1 - tanh(x)^2
\end{align*}
\subsubsection{Funzione sigmoide}
La funzione sigmoide traforma il valore di input in un valore compreso tra 0 ed 1. Per valori sempre più elevati il valore di ritorno dela funzione tende ad 1, in maniera speculare il valore tende a 0.
\begin{align*}
sigmoid(x) = \frac{1}{(1 + exp(-x))}
\end{align*}
\begin{align*}
sigmoid^{\prime}(x) = sigmoid(x)(1 - sigmoid(x))
\end{align*}
\subsubsection{Funzione di errore cross-entropy}
La funzione cross entropy è una funzione che misura la discrepanza tra i valori predetti e valori target di un apprendimento di tipo supervisionato ed è applicata nei problemi di classificazione.
\begin{align*}
CE(p,q) = -\sum_{i} p(i) \log(q(i))
\end{align*}
\begin{align*}
CE(p,q)^{\prime}= -\frac{p(i)}{q(i)}
\end{align*}
La funzione compara i valori di due distribuzioni di probabilità e nei casi in cui la funzione di attivazione dell'ultimo strato di una rete neurale non applichi una formula di normalizzazione dei valori rispetto alle probabilità di appartenenza nelle classi, risulta necessario ridefinire la funzione di errore includendo tale fase con ad esempio il softmax.\\
La regola della funzione cross entropy applicata con softmax è :
\begin{align*}
CE(p,q) = -\sum_{i} p(i) \log(q(i))
\end{align*}
\begin{align*}
CE(p,q)^{\prime} = -\frac{p(i)}{q(i)}
\end{align*}
\subsubsection{Funzione sum of squares}
La funzione sum of squares calcola attraverso l'elevamento a potenza e della sottrazione, la differenza tra due distribuzioni di probabilità ed è comunemente utilizzata nei problemi di regressione.
\begin{align*}
\text{s}(x) = \sum_{i=1}^{n} (y_i - t_i)^2
\end{align*}
\begin{align*}
\frac{\partial \text{s}(x)}{\partial x_i} = 2 (y_i - t_i)
\end{align*}

\subsection{Calcolo accuratezza}
Il calcolo dell'accuratezza è compiuto eseguendo la divisione tra il numero di elementi correttamente predetti e il numero totale di input del caso di test.
\begin{align*}
\text{accuracy} = \frac{\text{\# label corrette}}{\text{\# totale label}}
\end{align*}

\subsection{Fase di Analisi}
I dati raccolti durante la fase di addestramento sono poi interpretati con grafici nella fase di analisi. \\
La fase di analisi è compiuta dalla classe \texttt{Analysis} che ad ogni esecuzione di nuovo addestramento e con una nuova combinazione dei parametri definiti dall'utente, raccoglie: l'errore compiuto sul training e validation set, oltre che l'accuratezza ottenuta, ad ogni epoca, sul test set. \\
\begin{lstlisting}[language=Python]
class Analysis:
    def __init__(self):
        self.accuracies = []
        self.errors_train = []
        self.errors_valid = []
        self.test_accuracy = []
        self.results = {}

    def partial(self,neurons,rate,momentum,error_train,error_valid,accuracy):
        if neurons not in self.results:
            self.results[neurons] = {}
        if rate not in self.results[neurons]:
            self.results[neurons][rate] = {}
        self.results[neurons][rate][momentum] = {
            'error_train' : error_train,
            'error_valid' : error_valid,
            'accuracy' : accuracy
        }

    def save_charts(self):
        for neurons, nested_dict in self.results.items():
            for learning_rate, nested_nested_dict in nested_dict.items():
                for momentum, metriche in nested_nested_dict.items():
                    error_train = metriche['error_train']
                    error_valid = metriche['error_valid']
                    accuracy = metriche['accuracy']

                    plt.plot(error_train, label='Train Error')
                    plt.plot(error_valid, label='Valid Error')
                    plt.xlabel('Epoch')
                    plt.ylabel('Error')
                    plt.title(...)
                    plt.legend()
                    plt.savefig(self.get_result_path_error(...))
                    plt.close()

    def get_result_path_error(self, name):
        return os.path.join(os.getcwd(), "results/errors", name + ".png")
\end{lstlisting}
Il metodo \texttt{partial} raccoglie i risultati ottenuti ad ogni addestramento, mentre il metodo \texttt{save\_charts()} salva i risultati in un grafico che compara l'andamento dell'errore compiuto sul training set e sul validation set per covare eventuali casi di overfitting, ad esempio.