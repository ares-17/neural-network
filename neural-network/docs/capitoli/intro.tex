\chapter{Intro}
La relazione descrive le caratteristiche di un algoritmo proposto in grado di addestrare una rete neurale di tipo Feed-Forward con almeno due strati e densi. La fase di training della rete è compiuta sul dataset MNIST, un dataset di digit dei numeri 0-9. Deriva che la rete abbia come strato di output uno strato immutabile nella sua dimensione, di dieci neuroni. \\
In particolare la rete utilizza una versione dell'algoritmo di back propagation con gradient descent applicato con la variabile momentum.\\
Il principale scopo dell'implementazione è di allenare una rete neurale indipendentemente dal numero di neuroni e strati interni disposti, oltre che alle funzioni di attivazioni e di errore stabilite. Segue che la rete risulta particolarmente elastica a modifiche su tali parametri mantenendo al contempo le capacità di addestramento utilizzando algoritmi di forward e back propagation applicati al dataset MNIST. \\
La fase di analisi è applicata al variare di tre parametri: numero nodi strato intero, learning rate e momentum. Il numero di nodi strato interno è una variabile che determina l'architettura della rete; in tal senso può esser interessante valutare le prestazioni di architetture identiche. I restanti parametri definiscono rispettivamente quanto i neuroni sia in grado di apprendere, per singolo passo, e quanto peso diano al valore assunto precedentemente. 