 \documentclass[a4paper,11pt]{book}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{color}
\usepackage{url}
\usepackage{theorem}
\usepackage{textcomp}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{parskip}
\usepackage{soul} % for the command \hl
\usepackage{colortbl} % colore tabella
\usepackage{tikz} % per flowcharts
\usepackage{titlesec}
\usepackage{listings} % code snippet

%\usepackage[dvipsnames]{xcolor} da risolvere per ulteriori colori per snippet , come : NavyBlue
\usepackage{xcolor}
\usepackage{float} % with \begin{table}[H] for fixed table position
\usetikzlibrary{shapes, arrows} % per flowcharts
\graphicspath{{images/}}

\title{Parallel and Distribuited Computing}
\author{Schiavo Alessandro}
\date{\today}

\titleformat{\chapter}[display]
  {\normalfont\bfseries}{}{0pt}{\Huge} % remove label "Chapter" for every new chapter

% code snipper colors
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

% Definig a custom style:
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codepurple},
    %keywordstyle=\color{NavyBlue},
    keywordstyle=\color{blue},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize\bfseries,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=t,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
% -- Setting up the custom style:
\lstset{style=mystyle}


% definizione colore headers tabelle
\definecolor{header}{RGB}{247,230,113}

\begin{document}

\begin{titlepage}
    \begin{center}
        {{\Large
        {\textsc{Università degli studi di Napoli Federico II}}}} 
        \rule[0.1cm]{15.8cm}{0.1mm}
        {\small{\bf SCUOLA POLITECNICA E DELLE SCIENZE DI BASE\\  \vspace{3mm}
        DIPARTIMENTO DI INGEGNERIA ELETTRICA E TECNOLOGIE
DELL’INFORMAZIONE \\  \vspace{3mm}
CORSO DI LAUREA MAGISTRALE IN INFORMATICA}}
    \end{center}
    \vspace{15mm}
    \begin{center}
        {\LARGE{\bf Parallel and Distributed Computing }}\\
        \vspace{3mm}
        {\LARGE{\bf Elaborato 1}}\\
    \end{center}
    \vspace{40mm}
    \par
    \noindent
    \begin{minipage}[t]{0.47\textwidth}
        {\large{\bf Professore:}\\Giuliano Laccetti}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.47\textwidth}
        \raggedleft
        {\large{\bf Matricola:}\\ Alessandro Schiavo \\N97000423}
    \end{minipage}
    \vspace{20mm}
    \begin{center}
        {\large{\bf ANNO ACCADEMICO 2022 / 2023 }}
    \end{center}
\end{titlepage}

% \maketitle
\tableofcontents

\chapter{Definizione ed analisi del \\ problema}
\subsection{Analisi ambiente}
Si intende definire un algoritmo in grado di utilizzare appieno i calcolatori \underline{MIMD a memoria distribuita} per eseguire una somma di numeri reali. I calcolatori MIMD ( Multiple Instruction Multiple Data) a memoria distribuita si basano su architetture a memoria condivisa virtuale dove le diverse unità di elaborazione eseguono istruzioni su dati diversi. Tali unità sono associate ad una memoria privata, mentre i dati da condividere sono trasmessi con messaggi sincroni e asincroni. L'architettura MIMD quindi presenta caratteristiche ottimali per un ambiente di calcolo parallelo dove : 
\begin{itemize}
    \item le memorie non condivise non presentano problemi di sincronizzazione
    \item solo i dati da condividere sono trasmessi
    \item facile modifica del numero di unità di elaborazione
\end{itemize}
Al contempo gli svantaggi sono multipli e derivano dal tipo di architettura, che demanda molteplici responsabilità allo sviluppatore, come: bilanciare il carico di lavoro tra i vari nodi (coppia memoria-unità) e distribuire i dati necessari per l'elaborazione. 
L'operazione deve quindi sfruttare l'ambiente di sviluppo individuando la soluzione migliore in base ai nodi presenti e agli input forniti. \par 
In ambiente parallelo la complessità di tempo non è in grado di misurare l'efficienza degli algoritmi al variare del numero di processi, dato che non è proporzionale al numero di passi compiuti. Difatti ogni operazione è scomponibile in una componente sequenziale e una parallelizzabile.
\begin{quote}
    \centering
    $T(n) = T_s + \frac{T_c}{p}+ T_o(p)$ , con $T_o > 0$ se $p > 1$
\end{quote}
Dove $T_s$ risulta l'insieme delle operazioni esclusivamente sequenziali, $T_c$ l'insieme delle istruzioni eventualmente simultanee sul numero di processi $p$ e $T_o(p)$ il costo della comunicazione che è strettamente correlato al numero di processi. \par 
Dall'analisi dei tempi si evidenzia che al crescere del numero di processi, a causa della presenza di $T_o(p)$, non necessariamente corrisponde una riduzione del tempo di esecuzione totale. Risulta quindi inevitabile analizzare l'efficienza con strumenti adeguati all'ambiente parallelo.\par 
La funzione \textit{speed-up} $S(p)$ indica la riduzione del tempo di esecuzione da sequenziale a parallelo dimostrando quanto l'implementazione si presti alla parallelismo; mentre la funzione di \textit{efficienza} $E(p)$ indica la percentuale con la quale l'implementazione impiega le risorse a disposizione.

\subsection{Caratteristiche del problema}\label{caratteritiche_problema}
L'implementazione deve leggere i seguenti input:
\begin{itemize}
    \item $N$ : numero di elementi da sommare :
    \begin{itemize}
        \item se $N > 20$ l'algoritmo genera un insieme di numeri reali di cardinalità $N$ oppure
        \item se $N \leq 20$ l'algoritmo legge i numeri in input
    \end{itemize}
    \item $P$ strategia di comunicazione tra processi da applicare
    \item $ID$ identificativo del processo che stampa il risultato :
    \begin{itemize}
        \item se $ID = -1$ tutti i processi stampano il risultato
        \item se $0 \leq ID \leq (P - 1)$ il processo indicato stampa il risultato
    \end{itemize} 
\end{itemize}
\chapter{Definizione dell'agoritmo}
L'operazione somma di numeri reali presenta una struttra del tipo : lettura degli addendi e un ciclo di somme parziali per ottenere il risultato finale. L'operazione assume dunque le caratteristiche di un albero binario, dove le foglie sono gli addendi e i nodi dello stesso livello sono somme parziali ricavate dal livello precedente; segue che processi diversi possono eseguire rami diversi dell'albero e scambiare le informazioni solo quando necessario. \par 
La comunicazione tra processi è gestita con la libreria \underline{MPI} ed è impiegata per inizializzare l'ambiente per i processi disponibili e lo scambio di messaggi secondo varie strategie di comunicazione. \par 
Di seguito i macro passaggi che l'algoritmo compie.
 \begin{lstlisting}[language=C]
somma() {
  exit_status = check_input(...);

  if (exit_status != 0) {
    exit(exit_status);
  } else if (num_processi == 1) {
    sequenziale(...);
  }
  numero_elementi_processo = calculate_elem_proc(...);
  parse_input(...);
  buffer = local_calculation(...);
  communication_strategy(...);
  print_result(...);
}
\end{lstlisting}
La funzione \verb|communication_strategy()| definisce la strategia da utilizzare secondo l'input $P$ e di conseguenza tutti i processi, dopo aver calcolato la propria somma parziale, eseguendo scambi di messaggi secondo tre tipi di implementazione.
\subsection{Strategia I}
La prima strategia demanda ad un singolo processo il compito di sommare le somme parziali dei vari processi. Ponendo come processo delle somme parziali $id = 0$, si ottiene che:
\begin{itemize}
    \item i processi con $1 \leq id \leq (p-1)$ restano inutilizzati durante l'esecuzione dei livelli $l$ : $ 0 \leq l \leq (h-1)$
    \item a fine computazione solo il processo $id = 0$ contiene il risultato finale, aggiungendo un ulteriore scambio di messaggi in caso di lettura del risultato da altri processi
    \item il numero dei processi è proporzionale all'altezza dell'albero poichè un numero maggiore di processi implica ulteriori livelli con somme parziali da aggiungere al risultato finale
\end{itemize}

\subsection{Strategia II}
Per la seconda strategia i processi sono posti in gruppi di due e generalmente il primo riceve la somma parziale $s_1$ del secondo e comunica ad un altro gruppo di processi la somma $s_0 + s_1$. L'albero che si ottiene è un albero pieno con le foglie sullo stesso livello, quindi con altezza $h$ minima ottenibile $O(log_n)$. Tale classe di alberi binari ha però una limitazione : il numero delle foglie è pari e quindi il numero di processi.
Come per la prima strategia, il risultato è memorizzato solo in un processo.
\subsection{Strategia III}\label{strategia_3}
La rappresentazione grafica della terza strategia è identica alla seconda, questo perchè le somme parziali sono calcolate secondo lo stesso principio, ma con l'aggiunta che sono eseguite ulteriori comunicazioni tra rami diversi dell'albero, in modo tale che ogni foglia (processo) possegga il risultato totale. Le limitazioni che valgono per la seconda sono applicate anche alla terza strategia.

\chapter{Input e Output}
\chapter{Indicatori di errore}\label{indicatori_errore}
Sono presenti diversi indicatori di errore relativi al numero di input fornito, alla qualità dei valori e applicati eventuli controlli di relazione tra di essi. \par 
Come indicato alla sezione\ref{caratteritiche_problema} gli input sono :
\begin{enumerate}
    \item $N$ : numero di elementi da sommare
    \item $p$ : strategia di comunicazione dei messaggi
    \item $id$ : identificativo del processo che stampa il risultato
    \item $s_1,s_2,..,s_N$ valori d'input se $N < 21$ 
\end{enumerate}

\subsubsection{Errori numero elementi}
\begin{table}[H]
    \begin{tabular}{| p{0.5\textwidth} | p{0.5\textwidth} |}
        \hline
        \rowcolor{header}
        \textbf{Verifica} & \textbf{Descrizione} \\
        \hline
        \verb|N > 0| & 
        Verifica numero di elementi maggiore di zero \\
        \hline
        Posto \verb|M| il numero di elementi effettivamente passati in input: \verb|N != M AND N < 21| & 
        Se indicato $N < 21$ è compito dell'utente fornire in input lo stesso numero di numeri reali \\
        \hline
        Posto \verb|R| il numero di processi
        : \verb|(N/2) < R| & 
        Devono esser presenti almeno due numeri reali per processo\\
        \hline
    \end{tabular}
    \caption{Indicatori di errore per il numero di elementi}
    \label{tab:Indicatori di errore per il numero di elementi}
\end{table}

\subsubsection{Errori strategia}
\begin{table}[H]
    \begin{tabular}{| p{0.5\textwidth} | p{0.5\textwidth} |}
        \hline
        \rowcolor{header}
        \textbf{Verifica} & \textbf{Descrizione} \\
        \hline
        \verb|P < 1 OR P > 3| & 
        Verifica che numero indicato corrisponda alla prima , seconda o terza strategia \\
        \hline
        Posto \verb|P| il numero di processi e \verb|IS_POW(P)| una funzione che determina le potenze di due: \verb|S != S1 AND IS_POW(P)| & 
        Se la strategia è la seconda o la terza, il numero di processi deve esser potenza di due \\
        \hline
    \end{tabular}
    \caption{Indicatori di errore per strategia}
    \label{tab:Indicatori di errore per strategia}
\end{table}

\subsubsection{Errori identificativo}
\begin{table}[H]
    \begin{tabular}{| p{0.5\textwidth} | p{0.5\textwidth} |}
        \hline
        \rowcolor{header}
        \textbf{Verifica} & \textbf{Descrizione} \\
        \hline
        \verb|ID < -1 OR ID > (P-1)| & 
        Posto \verb|P| il numero di processi, determina che l'id indicato non sia al di fuori del range\\
        \hline
    \end{tabular}
    \caption{Indicatori di errore identificativo}
    \label{tab:Indicatori di errore identificativo}
\end{table}

\subsubsection{Warnings}
I \textit{warnings} sono delle verifiche aggiuntive eseguite e un loro fallimento non implica la terminazione dell'algoritmo, ma eventualmente sono modificati degli input per proseguire.
\begin{table}[H]
    \begin{tabular}{| p{0.5\textwidth} | p{0.5\textwidth} |}
        \hline
        \rowcolor{header}
        \textbf{Verifica} & \textbf{Descrizione} \\
        \hline
        Posto \verb|P| il numero di processi, \verb|P = 1| & 
        Avvisa a video che il calcolo sarà eseguito sequenzialmente\\
        \hline
        Posto \verb|S3| come terza strategia: \verb|S \neq S3 AND| \verb| (ID != 0 OR ID = -1)| & 
        Se selezionata la prima o seconda strategia solo il primo processo contiene il risultato da stampare, quindi se in input è specificato un processo diverso dal primo allora la verifica pone \verb|ID = 1| \\
        \hline
    \end{tabular}
    \caption{Indicatori di errore identificativo}
    \label{tab:Indicatori di errore identificativo}
\end{table}

\chapter{Subroutine}
Le istruzioni che compongono l'operazione somma di numeri reali sono distribuite in micro operazioni (subroutine) che facilitano l'identificazione delle fasi di calcolo. Le principali subroutine sono elencate sotto forma di istruzioni e correlate da un breve riassunto delle principali caratteristiche ed eventuali implementazioni della libreria.

\subsection{Lettura degli input}
\begin{lstlisting}[language=C]
void check_input(int memum, 
    int * exit_status, 
    int argc,
    int * strategy,
    char ** argv, 
    int * num_items_input, 
    int * id);
\end{lstlisting}
La funzione demanda esclusivamente al primo processo la lettura degli input, eseguendo semplici \underline{controlli di qualità e quantità}. I controlli determinano una serie di valori che sono condivisi ai processi dello stesso communicator, in particolare \verb|exit_status| che individua casi di errori di terminazione del programma. Per la condivisione dei dati, sono eseguite in serie chiamate alla funzione della libreria \verb|MPI_Bcast|.

\subsection{Decodifica dell'input}
\begin{lstlisting}[language=C]
void parse_input(char ** argv, 
    int memum, 
    int num_data_proc, 
    int num_total_items, 
    double ** recv_buffer);
\end{lstlisting}
La lista dei numeri reali inizializzabile in due modi : i numeri possono esser forniti dall'utente oppure esser generati casualmente.\par 
Nel primo caso il processo con $id=0$ legge un numero $n$ di elementi , $2 \leq n \leq 20$, e li converte da stringhe di input a variabili di tipo \verb|double|. \par 
La cardinalità ristretta di $n$ garantisce di non creare tempi di attesa della decodifica abbastanza lunghi da non sfruttare in maniera adeguata tutti i processi. Una volta decodificati gli input è chiamata la funzione \verb|distribuite_data| \par
Nel secondo caso invece, ogni processo genera e memorizza autonomamente una quantità variabile di numeri casuali nella propria lista di riferimento. Il numero di elementi per processo è precedentemente determinato. 

\subsection{Distribuzione dei dati}
\begin{lstlisting}[language=C]
void distribuite_data(int memum, 
    double * send_buffer, 
    int num_data_proc, 
    double ** recv_buffer);
\end{lstlisting}
La subroutine distribuisce \verb|send_buffer| ai processi del communicator utilizzando le funzioni della libreria \verb|MPI_Gather| e \verb|MPI_Scatterv|.\par 
La prima raccoglie il numero di reali che ogni processo si spetta e memorizza le informazioni in una lista, dove la posizione $i$ corrisponde al processo $p_i$. \par 
La seconda funzione distribuisce la lista dei numeri reali impiegando due liste: una identifica il numero di reali che ogni processo si aspetta (determinato precedentemente) e la seconda indica la porzione della lista che ogni processo ottiene. Per la distribuzione è impiegata la variante di \verb|MPI_Scatter| per distribuire ad ogni processo un numero diverso di elementi.

\subsection{Lettura delle performance}
\begin{lstlisting}[language=C]
void start_performance(double * start_time);
void read_performance(double start_time_proc, int memum);
\end{lstlisting}
Le funzioni determinano il tempo massimo impiegato per svolgere le operazioni di calcolo richieste. \par 
Con \verb|start_performance| i processi sono sincronizzati sulla stessa istruzione con la funzione della libreria \verb|MPI_Barrier|, per far sì che tutti i processi del communicator siano pronti per eseguire le operazioni che seguono. \par 
Con \verb|read_performance| è impiegata la libreria con \verb|MPI_Reduce| che identifica il massimo dei tempi ottenuti da ciascun processo. 

\subsection{Strategie}
\subsubsection{Strategia I}
\begin{lstlisting}[language=C]
void first_strategy(int memum, double * local_sum) {
  if (memum == 0) {
    double sum_proc = 0;
    int memum_proc = 0;
    for (memum_proc = 1; memum_proc < num_procs; memum_proc++) {
      MPI_Recv( &sum_proc, 1, MPI_DOUBLE, memum_proc,
        TAG_STRATEGY(memum_proc), MPI_COMM_WORLD,
        MPI_STATUS_IGNORE);
        
      *local_sum += sum_proc;
    }
  } else {
    MPI_Send(local_sum, 1, MPI_DOUBLE, 0,
        TAG_STRATEGY(memum), MPI_COMM_WORLD);
  }
}
\end{lstlisting}
La prima strategia fa sì che ogni processo $p_i$, con $1 \leq id \leq (P-1)$ e con $P$ numero di processi, invii la propria somma parziale al processo $p_0$.

\subsubsection{Strategia II}
\begin{lstlisting}[language=C]
void second_strategy(int memum, double * partial_sum) {
  int * exp2;
  exponentials( & exp2);
  int steps = log2(num_procs);
  double tmp_buff;
  int step = 0;
  
  for (step = 0; step < steps; step++) {
    if ((memum % exp2[step]) == 0) {
      if ((memum % exp2[step + 1]) == 0) {
        MPI_Recv( & tmp_buff, 1, MPI_DOUBLE, 
            (memum + exp2[step]), TAG_STRATEGY(step),
             MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        *partial_sum += tmp_buff;
      } else {
        MPI_Send(partial_sum, 1, MPI_DOUBLE, 
            (memum - exp2[step]), TAG_STRATEGY(step), MPI_COMM_WORLD);
      }
    }
  }
  if (exp2 != NULL) {
    free(exp2);
  }
}
\end{lstlisting}
Per la seconda strategia è generata una lista di valori che corrispondenti alle potenze di due e riusata da tutti i processi. Dopodichè sono calcolati di volta in volta i processi che ricevono e che inaviano la propria somma parziale. Il controllo \verb|memum % exp2[step]) == 0| fa sì che ogni livello, il numero di processi coinvolti nella somma parziale siano dimezzati rispetto al livello precedente.

\subsubsection{Strategia III}
\begin{lstlisting}[language=C]
void third_strategy(int memum, double * partial_sum) {
  int steps = 0;
  int * exp2;
  exponentials( & exp2);
  steps = log2(num_procs);
  int another_rank = 0;
  int level_multiple = 0;
  int level = 0;
  
  for (level = 0; level < steps; level++) {
    level_multiple = exp2[level];
    if ((memum % (exp2[level + 1])) < level_multiple) {
      another_rank = (memum + level_multiple);
      MPI_Send(partial_sum, 1, MPI_DOUBLE, another_rank,
        TAG_STRATEGY(level), MPI_COMM_WORLD);
      
      double buff = 0;
      
      MPI_Recv( & buff, 1, MPI_DOUBLE, another_rank
        TAG_STRATEGY(level),MPI_COMM_WORLD   
                        MPI_STATUS_IGNORE);
      * partial_sum = * partial_sum + buff;
    } else {
      another_rank = (memum - level_multiple);
      MPI_Send(partial_sum, 1, MPI_DOUBLE, another_rank,
        TAG_STRATEGY(level), MPI_COMM_WORLD);
      
      double buff = 0;
      
      MPI_Recv( & buff, 1, MPI_DOUBLE, another_rank,
       TAG_STRATEGY(level), MPI_COMM_WORLD, MPI_STATUS_IGNORE);
      *partial_sum = * partial_sum + buff;
    }
  }
  if (exp2 != NULL) {
    free(exp2);
  }
}
\end{lstlisting}
La terza strategia si avvale anch'essa di una lista di potenze di due per determinare le comunicazioni da compiere. In tale strategia sono coinvolti tutti i processi in qualsiasi livello, garantendo comunque un numero di livelli minimo per l'esecuzione (vedi \ref{strategia_3}).\par 
Ogni processo invia e riceve la somma parziale memorizzata e il processo con il quale comunicare  è calcolato in base al proprio identificativo.

\chapter{Analisi dei tempi}
\chapter{Esempi d'uso}
I parametri forniti in input determinano il comportamento dell'algoritmo; modificando di conseguenza i tempi di esecuzione. \par 
\subsubsection{Ogni processo stampa il risultato}
La variabile che indica il processo che stampa il risultato è $id$ : se assume il valore di $-1$, tutti i processi stampano la propria somma parziale.
\begin{lstlisting}[language=C]
mpiexec -np 4 ./primo_elaborato 10000 3 -1

Somma totale : 506429.100210, da id = 0
Somma totale : 506429.100210, da id = 1
Somma totale : 506429.100210, da id = 2
Somma totale : 506429.100210, da id = 3
\end{lstlisting}
Al programma sono resi disponibili quattro processi con : mille numeri da generare casualmente, da ripartire nei quattro processi e indicando la terza strategia.
\begin{lstlisting}[language=C]
mpiexec -np 3 ./primo_elaborato 10000 3 -1

Strategia impostata sul valore di 1 poiché il numero 
di processi non è potenza di 2...
Se è selezionata la prima o la seconda strategia allora,
solo il primo processo (id = 0) ha il risultato totale!
Per tale motivo id è posto a 0...

Somma totale : 512058.290683, da id = 0
\end{lstlisting}
Come specificato al capitolo \ref{indicatori_errore}, la terza e seconda strategia non sono applicabili su un numero di processi non potenza di due; inoltre per la prima strategia solo il primo processo può stampare il risultato.

\subsubsection{Lettura numeri reali in input}
\begin{lstlisting}[language=C]
mpiexec -np 2 ./primo_elaborato 10 3 1 1 2 3 4 5 6 7 8 9 10

Somma totale : 55.000000, da id = 1
\end{lstlisting}
La lista di numeri reali è letta in input solo se il numero indicato come primo parametro segue : $2 \leq N \leq 20$. 
\begin{lstlisting}[language=C]
mpiexec -np 2 ./primo_elaborato 10 3 1 1 2 3 4 5 6 7 8 9 

Il numero totale di elementi da sommare non corrisponde 
agli elementi effettivamente passati in input 
\end{lstlisting}
Se il numero degli elementi in lista non corrisponde al numero di elementi indicato come primo parametro, l'esecuzione termine con un errore.
\chapter{Appendice}

\end{document}
